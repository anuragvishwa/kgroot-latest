# ═══════════════════════════════════════════════════════════════════════════
# KG RCA AGENT - Client Configuration
# ═══════════════════════════════════════════════════════════════════════════

# Client identification and authentication
client:
  # Client ID provided by server (e.g., "client-acme-abc123")
  id: ""

  # API key for authentication
  apiKey: ""

  # Server connection details
  serverUrl: "https://api.kg-rca.yourcompany.com"

  # Kafka connection
  kafka:
    brokers: "kafka.kg-rca.yourcompany.com:9092"
    sasl:
      enabled: false  # Set to true for SSL/SASL authentication
      mechanism: SCRAM-SHA-512
      username: ""  # Same as client.id
      password: ""  # Provided by server

  # Namespace to monitor (default: all accessible namespaces)
  monitoredNamespaces: []  # Empty means all accessible

# ───────────────────────────────────────────────────────────────────────────
# State Watcher - Kubernetes Resource Monitoring
# ───────────────────────────────────────────────────────────────────────────
stateWatcher:
  enabled: true
  image:
    repository: anuragvishwa/kg-state-watcher
    tag: "1.0.2"
    pullPolicy: IfNotPresent

  replicaCount: 1

  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 512Mi

  # Prometheus HTTP endpoint used for /api/v1/targets scraping.
  # Override this when your kube-prometheus-stack release uses a different service name.
  prometheusUrl: "http://kube-prometheus-stack-prometheus.monitoring.svc:9090"

  env:
    KAFKA_BROKERS: ""  # Populated from client.kafka.brokers
    KAFKA_TOPIC_RESOURCE: "state.k8s.resource"
    KAFKA_TOPIC_TOPOLOGY: "state.k8s.topology"
    WATCH_NAMESPACES: ""  # Populated from client.monitoredNamespaces

  # Explicit topic overrides for templates
  topicResource: ""
  topicTopology: ""
  topicPromTargets: ""

# ───────────────────────────────────────────────────────────────────────────
# Vector - Log Collection
# ───────────────────────────────────────────────────────────────────────────
vector:
  enabled: true
  image:
    repository: timberio/vector
    tag: "0.34.0-alpine"
    pullPolicy: IfNotPresent

  # DaemonSet to collect logs from all nodes
  daemonset: true

  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 512Mi

  config:
    sources:
      kubernetes_logs:
        type: kubernetes_logs
        exclude_paths_glob_patterns:
          - "**/kube-system/**"
          - "**/kube-public/**"

    transforms:
      normalize:
        type: remap
        inputs: ["kubernetes_logs"]
        source: |
          .client_id = "{{ .client.id }}"
          .event_time = now()

    sinks:
      kafka:
        type: kafka
        inputs: ["normalize"]
        bootstrap_servers: ""  # Populated from client.kafka.brokers
        topic: ""  # Set via vector.kafkaTopic; default resolves to logs.normalized
        encoding:
          codec: json
  # Optional override for logs topic (default: logs.normalized)
  kafkaTopic: ""
  # Optional mirror of raw container logs directly to Kafka
  rawLogsTopic: ""  # e.g., "raw.k8s.logs" to also publish raw logs

# ───────────────────────────────────────────────────────────────────────────
# Alertmanager Webhook (Vector-based)
# Accept Alertmanager POSTs and forward to Kafka
# ───────────────────────────────────────────────────────────────────────────
alertsWebhook:
  enabled: true
  port: 9090
  # Raw topic for storing original Alertmanager payloads (optional)
  rawTopic: "raw.prom.alerts"

# ───────────────────────────────────────────────────────────────────────────
# Event Exporter - Kubernetes Events
# ───────────────────────────────────────────────────────────────────────────
eventExporter:
  enabled: true
  image:
    repository: opsgenie/kubernetes-event-exporter
    tag: "latest"
    pullPolicy: IfNotPresent

  replicaCount: 1

  resources:
    requests:
      cpu: 50m
      memory: 128Mi
    limits:
      cpu: 200m
      memory: 256Mi

  config:
    route:
      routes:
        - match:
            - receiver: kafka
        - match:
            - receiver: kafka-raw
    receivers:
      - name: kafka
        kafka:
          brokers: []  # Populated from client.kafka.brokers
          topic: ""  # Set via eventExporter.kafkaTopic; default resolves to events.normalized
      - name: kafka-raw
        kafka:
          brokers: []  # Populated from client.kafka.brokers
          topic: ""  # Set via eventExporter.rawTopic; default resolves to raw.k8s.events

  # Optional override for events topic (default: events.normalized)
  kafkaTopic: ""
  # Optional mirror to raw events topic
  rawTopic: ""

# ───────────────────────────────────────────────────────────────────────────
# Prometheus Agent - Metrics Collection
# ───────────────────────────────────────────────────────────────────────────
prometheusAgent:
  enabled: true
  image:
    repository: prom/prometheus
    tag: "latest"
    pullPolicy: IfNotPresent

  replicaCount: 1

  resources:
    requests:
      cpu: 200m
      memory: 512Mi
    limits:
      cpu: 1000m
      memory: 2Gi

  # Remote write to server
  remoteWrite:
    enabled: true
    url: "{{ .client.serverUrl }}/api/v1/write"
    headers:
      Authorization: "Bearer {{ .client.apiKey }}"

  config:
    global:
      scrape_interval: 30s
      evaluation_interval: 30s

    scrape_configs:
      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true

# ───────────────────────────────────────────────────────────────────────────
# Alert Receiver - Prometheus Alerts
# ───────────────────────────────────────────────────────────────────────────
alertReceiver:
  enabled: true
  image:
    repository: anuragvishwa/kg-alert-receiver
    tag: "1.0.8"
    pullPolicy: Always

  replicaCount: 2

  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 512Mi

  env:
    KAFKA_BROKERS: ""  # Populated from client.kafka.brokers
    KAFKA_TOPIC: "alerts.raw"
    CLIENT_ID: ""  # Populated from client.id

# ───────────────────────────────────────────────────────────────────────────
# RBAC - Service Account and Permissions
# ───────────────────────────────────────────────────────────────────────────
rbac:
  create: true

  # Cluster-wide read permissions
  clusterRole:
    rules:
      - apiGroups: [""]
        resources: ["pods", "services", "endpoints", "nodes", "events", "namespaces", "configmaps"]
        verbs: ["get", "list", "watch"]
      - apiGroups: ["events.k8s.io"]
        resources: ["events"]
        verbs: ["get", "list", "watch"]
      - apiGroups: ["discovery.k8s.io"]
        resources: ["endpointslices"]
        verbs: ["get", "list", "watch"]
      - apiGroups: ["apps"]
        resources: ["deployments", "replicasets", "statefulsets", "daemonsets"]
        verbs: ["get", "list", "watch"]
      - apiGroups: ["batch"]
        resources: ["jobs", "cronjobs"]
        verbs: ["get", "list", "watch"]

serviceAccount:
  create: true
  name: kg-rca-agent

# ───────────────────────────────────────────────────────────────────────────
# Network Policies
# ───────────────────────────────────────────────────────────────────────────
networkPolicy:
  enabled: false

  egress:
    # Allow outbound to server
    - to:
      - podSelector: {}
      ports:
      - protocol: TCP
        port: 443
    # Allow DNS
    - to:
      - namespaceSelector: {}
      ports:
      - protocol: UDP
        port: 53
